{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. ìŒì„± ëª¨ë¸ í•™ìŠµ\n",
    "### Mell + LSTM ë‹¤ì¤‘ ë¶„ë¥˜ (4ê°œ í´ë˜ìŠ¤)\n",
    "- í´ë˜ìŠ¤ 0: ë¹„ê°•ì¡°\n",
    "- í´ë˜ìŠ¤ 1: ì¹¨ë¬µ+ê°•ì¡°\n",
    "- í´ë˜ìŠ¤ 2: ìŒ ë†’ë‚®ì´ ë³€í™”+ê°•ì¡°\n",
    "- í´ë˜ìŠ¤ 3: í¬ê²Œ ë§í•¨+ê°•ì¡°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ì¤‘... (Mel-Spectrogram)\n",
      "\n",
      "ğŸš€ ìµœì¢… ëª¨ë¸ í•™ìŠµ ì‹œì‘ (100 Epochs)...\n",
      "  [Ep 1] New Best F1: 0.6276 -> Saved!\n",
      "  [Ep 2] New Best F1: 0.6343 -> Saved!\n",
      "  [Ep 4] New Best F1: 0.6971 -> Saved!\n",
      "  [Ep 12] New Best F1: 0.7036 -> Saved!\n",
      "  [Ep 13] New Best F1: 0.7109 -> Saved!\n",
      "  [Ep 18] New Best F1: 0.7326 -> Saved!\n",
      "  [Ep 29] New Best F1: 0.7343 -> Saved!\n",
      "  [Ep 37] New Best F1: 0.7358 -> Saved!\n",
      "  [Ep 52] New Best F1: 0.7422 -> Saved!\n",
      "\n",
      "==================================================\n",
      "ğŸ‰ í•™ìŠµ ì™„ë£Œ! ì €ì¥ëœ íŒŒì¼: best_bi_lstm.pth\n",
      "ğŸ† ìµœì¢… ìµœê³  F1 Score: 0.7422\n",
      "==================================================\n",
      "ğŸ‘‰ ì´ì œ ì¶”ë¡ (Inference) ì½”ë“œì—ì„œ MODEL_PATH = 'best_bi_lstm.pth' ë¡œ ë°”ê¿”ì„œ ì“°ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# ==========================================\n",
    "# â–¼ [ì„¤ì •] ì €ì¥í•  íŒŒì¼ëª… ì •ì˜\n",
    "# ==========================================\n",
    "DATA_FOLDER = r\"/home/stu/ai_project/voice_data\"\n",
    "SAVE_MODEL_PATH = \"best_bi_lstm.pth\"  \n",
    "\n",
    "\n",
    "SR = 16000\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 512\n",
    "WINDOW_SIZE = 50\n",
    "BATCH_SIZE = 256 \n",
    "EPOCHS = 100     \n",
    "LR = 0.001\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# ==========================================\n",
    "# 1. ëª¨ë¸ ì •ì˜ (Winner: Bi-LSTM)\n",
    "# ==========================================\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_classes=4):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])\n",
    "\n",
    "# ==========================================\n",
    "# 2. ë°ì´í„° ë¡œë“œ (Mel-Spectrogram)\n",
    "# ==========================================\n",
    "def create_dataset():\n",
    "    print(\"ğŸ“‚ ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ì¤‘... (Mel-Spectrogram)\")\n",
    "    all_files = [f for f in os.listdir(DATA_FOLDER) if f.endswith('.wav')]\n",
    "    train_files, val_files = train_test_split(all_files, test_size=0.2, random_state=42)\n",
    "\n",
    "    def process(files):\n",
    "        X_list, y_list = [], []\n",
    "        for f in files:\n",
    "            try:\n",
    "                path = os.path.join(DATA_FOLDER, f)\n",
    "                y, _ = librosa.load(path, sr=SR)\n",
    "                y = librosa.util.normalize(y)\n",
    "                \n",
    "                # Mel-Spec\n",
    "                mel = librosa.feature.melspectrogram(y=y, sr=SR, n_mels=80, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "                feat = librosa.power_to_db(mel, ref=np.max).T\n",
    "                \n",
    "                scaler = StandardScaler()\n",
    "                feat_norm = scaler.fit_transform(feat)\n",
    "                \n",
    "                # Auto Labeling\n",
    "                num_frames = len(feat_norm)\n",
    "                labels = np.zeros(num_frames, dtype=int)\n",
    "                rms = librosa.feature.rms(y=y, frame_length=N_FFT, hop_length=HOP_LENGTH)[0][:num_frames]\n",
    "                cent = librosa.feature.spectral_centroid(y=y, sr=SR, n_fft=N_FFT, hop_length=HOP_LENGTH)[0][:num_frames]\n",
    "                \n",
    "                feat_norm = feat_norm[:len(rms)]; labels = labels[:len(rms)]\n",
    "                rms_z = (rms - np.mean(rms)) / (np.std(rms) + 1e-6)\n",
    "                cent_z = (cent - np.mean(cent)) / (np.std(cent) + 1e-6)\n",
    "                \n",
    "                for i in range(len(labels)):\n",
    "                    if i > 5 and np.mean(rms_z[i-5:i]) < -0.5 and rms_z[i] > 0: labels[i] = 1\n",
    "                    elif rms_z[i] > 1.5: labels[i] = 3\n",
    "                    elif cent_z[i] > 1.5: labels[i] = 2\n",
    "                \n",
    "                # Windowing\n",
    "                for i in range(0, len(feat_norm) - WINDOW_SIZE, 10):\n",
    "                    X_list.append(feat_norm[i : i + WINDOW_SIZE])\n",
    "                    y_list.append(labels[i + WINDOW_SIZE - 1])\n",
    "            except: pass\n",
    "        return np.array(X_list), np.array(y_list)\n",
    "\n",
    "    X_train, y_train = process(train_files)\n",
    "    X_val, y_val = process(val_files)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "# ==========================================\n",
    "# 3. í•™ìŠµ ë° ì €ì¥ ì‹¤í–‰\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    X_train, y_train, X_val, y_val = create_dataset()\n",
    "    \n",
    "    cls = np.unique(y_train)\n",
    "    w = compute_class_weight('balanced', classes=cls, y=y_train)\n",
    "    cw = torch.ones(NUM_CLASSES).to(device)\n",
    "    for c, weight in zip(cls, w): cw[int(c)] = weight\n",
    "    \n",
    "    train_dl = DataLoader(TensorDataset(torch.FloatTensor(X_train), torch.LongTensor(y_train)), batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_dl = DataLoader(TensorDataset(torch.FloatTensor(X_val), torch.LongTensor(y_val)), batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    input_dim = X_train.shape[2]\n",
    "    model = BiLSTM(input_dim, num_classes=NUM_CLASSES).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    criterion = nn.CrossEntropyLoss(weight=cw)\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "    \n",
    "    print(f\"\\nğŸš€ ìµœì¢… ëª¨ë¸ í•™ìŠµ ì‹œì‘ ({EPOCHS} Epochs)...\")\n",
    "    \n",
    "    for ep in range(EPOCHS):\n",
    "        model.train()\n",
    "        for bx, by in train_dl:\n",
    "            bx, by = bx.to(device), by.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(bx), by)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        model.eval()\n",
    "        preds, targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for bx, by in val_dl:\n",
    "                bx = bx.to(device)\n",
    "                outputs = model(bx)\n",
    "                preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "                targets.extend(by.numpy())\n",
    "        \n",
    "        score = f1_score(targets, preds, average='macro', zero_division=0)\n",
    "        \n",
    "        if score > best_f1:\n",
    "            best_f1 = score\n",
    "            torch.save(model.state_dict(), SAVE_MODEL_PATH) \n",
    "            print(f\"  [Ep {ep+1}] New Best F1: {score:.4f} -> Saved!\")\n",
    "            \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"ğŸ‰ í•™ìŠµ ì™„ë£Œ! ì €ì¥ëœ íŒŒì¼: {SAVE_MODEL_PATH}\")\n",
    "    print(f\"ğŸ† ìµœì¢… ìµœê³  F1 Score: {best_f1:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"ğŸ‘‰ ì´ì œ ì¶”ë¡ (Inference) ì½”ë“œì—ì„œ MODEL_PATH = 'best_bi_lstm.pth' ë¡œ ë°”ê¿”ì„œ ì“°ì„¸ìš”!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
