{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d048779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stu/anaconda3/envs/ai_project_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/stu/anaconda3/envs/ai_project_env/lib/python3.10/site-packages/df/io.py:9: UserWarning: `torchaudio.backend.common.AudioMetaData` has been moved to `torchaudio.AudioMetaData`. Please update the import path.\n",
      "  from torchaudio.backend.common import AudioMetaData\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ ì´ 3ê°œì˜ ì˜ìƒì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
      "\n",
      "[1/3] ì²˜ë¦¬ ì¤‘: 20251215_193652.mp4\n",
      "\u001b[32m2025-12-15 20:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on torch 2.6.0+cu124\u001b[0m\n",
      "\u001b[32m2025-12-15 20:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on host n9\u001b[0m\n",
      "\u001b[32m2025-12-15 20:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mLoading model settings of DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-12-15 20:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mUsing DeepFilterNet3 model at /home/stu/.cache/DeepFilterNet/DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-12-15 20:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mInitializing model `deepfilternet3`\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any of the parent directories): .git\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-15 20:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mFound checkpoint /home/stu/.cache/DeepFilterNet/DeepFilterNet3/checkpoints/model_120.ckpt.best with epoch 120\u001b[0m\n",
      "\u001b[32m2025-12-15 20:17:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on device cuda:0\u001b[0m\n",
      "\u001b[32m2025-12-15 20:17:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mModel loaded\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Kss]: Because there's no supported C++ morpheme analyzer, Kss will take pecab as a backend. :D\n",
      "For your information, Kss also supports mecab backend.\n",
      "We recommend you to install mecab or konlpy.tag.Mecab for faster execution of Kss.\n",
      "Please refer to following web sites for details:\n",
      "- mecab: https://github.com/hyunwoongko/python-mecab-kor\n",
      "- konlpy.tag.Mecab: https://konlpy.org/en/latest/api/konlpy.tag/#mecab-class\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â˜€ï¸ Solar ë¶„ì„ ì‹œì‘ (23 ë¬¸ì¥)...\n",
      "      -> 1 ~ 20 ë¬¸ì¥ ì™„ë£Œ\n",
      "      -> 21 ~ 23 ë¬¸ì¥ ì™„ë£Œ\n",
      "   ğŸ’ RoBERTa í…ì„œ ì¶”ì¶œ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stu/anaconda3/envs/ai_project_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… ê°œë³„ ì²˜ë¦¬ ì™„ë£Œ: 23 ë¬¸ì¥\n",
      "\n",
      "[2/3] ì²˜ë¦¬ ì¤‘: 20251215_194052.mp4\n",
      "\u001b[32m2025-12-15 20:18:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mLoading model settings of DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-12-15 20:18:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mUsing DeepFilterNet3 model at /home/stu/.cache/DeepFilterNet/DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-12-15 20:18:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mInitializing model `deepfilternet3`\u001b[0m\n",
      "\u001b[32m2025-12-15 20:18:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mFound checkpoint /home/stu/.cache/DeepFilterNet/DeepFilterNet3/checkpoints/model_120.ckpt.best with epoch 120\u001b[0m\n",
      "\u001b[32m2025-12-15 20:18:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on device cuda:0\u001b[0m\n",
      "\u001b[32m2025-12-15 20:18:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mModel loaded\u001b[0m\n",
      "   â˜€ï¸ Solar ë¶„ì„ ì‹œì‘ (23 ë¬¸ì¥)...\n",
      "      -> 1 ~ 20 ë¬¸ì¥ ì™„ë£Œ\n",
      "      -> 21 ~ 23 ë¬¸ì¥ ì™„ë£Œ\n",
      "   ğŸ’ RoBERTa í…ì„œ ì¶”ì¶œ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stu/anaconda3/envs/ai_project_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… ê°œë³„ ì²˜ë¦¬ ì™„ë£Œ: 23 ë¬¸ì¥\n",
      "\n",
      "[3/3] ì²˜ë¦¬ ì¤‘: 20251215_195125.mp4\n",
      "\u001b[32m2025-12-15 20:20:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mLoading model settings of DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-12-15 20:20:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mUsing DeepFilterNet3 model at /home/stu/.cache/DeepFilterNet/DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2025-12-15 20:20:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mInitializing model `deepfilternet3`\u001b[0m\n",
      "\u001b[32m2025-12-15 20:20:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mFound checkpoint /home/stu/.cache/DeepFilterNet/DeepFilterNet3/checkpoints/model_120.ckpt.best with epoch 120\u001b[0m\n",
      "\u001b[32m2025-12-15 20:20:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on device cuda:0\u001b[0m\n",
      "\u001b[32m2025-12-15 20:20:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mModel loaded\u001b[0m\n",
      "   â˜€ï¸ Solar ë¶„ì„ ì‹œì‘ (25 ë¬¸ì¥)...\n",
      "      -> 1 ~ 20 ë¬¸ì¥ ì™„ë£Œ\n",
      "      -> 21 ~ 25 ë¬¸ì¥ ì™„ë£Œ\n",
      "   ğŸ’ RoBERTa í…ì„œ ì¶”ì¶œ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stu/anaconda3/envs/ai_project_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… ê°œë³„ ì²˜ë¦¬ ì™„ë£Œ: 25 ë¬¸ì¥\n",
      "\n",
      "==================================================\n",
      "ğŸš€ ëª¨ë“  ì˜ìƒ ì²˜ë¦¬ ì™„ë£Œ! ë³‘í•© íŒŒì¼ ìƒì„± ì¤‘...\n",
      "âœ… [í†µí•© ì™„ë£Œ] í…ì„œ ê°œìˆ˜: 71ê°œ\n",
      "   ğŸ’¾ ì €ì¥ ê²½ë¡œ: /home/stu/ai_project/ì‹œì—°ì—°/total_tensor.pt\n",
      "âœ… [í†µí•© ì™„ë£Œ] JSON ë°ì´í„° ê°œìˆ˜: 71ê°œ\n",
      "   ğŸ’¾ ì €ì¥ ê²½ë¡œ: /home/stu/ai_project/ì‹œì—°ì—°/total_text.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import whisper\n",
    "import kss\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "from openai import OpenAI\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from df.enhance import enhance, init_df, load_audio, save_audio\n",
    "\n",
    "# =======================\n",
    "# âš™ï¸ ì„¤ì •ê°’\n",
    "# =======================\n",
    "SOLAR_API_KEY = \"up_EWqzIcLH0bVwkJgPRyb4CYrJCCEwy\"\n",
    "SOLAR_BASE_URL = \"https://api.upstage.ai/v1/solar\"\n",
    "MODEL_ID = \"solar-pro2\"\n",
    "VIDEO_DIR = \"/home/stu/ai_project/ì‹œì—°\"     \n",
    "RESULT_DIR = \"/home/stu/ai_project/ì‹œì—°\"      \n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "@dataclass\n",
    "class SentenceSegment:\n",
    "    index: int\n",
    "    start: float\n",
    "    end: float\n",
    "    text: str\n",
    "\n",
    "# =======================\n",
    "# 1. ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ ì²˜ë¦¬ í•¨ìˆ˜\n",
    "# =======================\n",
    "def extract_audio_from_video(video_path: str) -> str:\n",
    "    audio_path = video_path.rsplit('.', 1)[0] + \".wav\"\n",
    "    if os.path.exists(audio_path):\n",
    "        return audio_path\n",
    "    command = [\"ffmpeg\", \"-y\", \"-i\", video_path, \"-ac\", \"1\", \"-ar\", \"48000\", \"-vn\", audio_path]\n",
    "    subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)\n",
    "    return audio_path\n",
    "\n",
    "def remove_noise_and_add_comfort(input_path: str) -> str:\n",
    "    model, df_state, _ = init_df()\n",
    "    audio, _ = load_audio(input_path, sr=df_state.sr())\n",
    "    enhanced_audio = enhance(model, df_state, audio)\n",
    "    \n",
    "    clean_path = input_path.replace(\".wav\", \"_clean.wav\")\n",
    "    save_audio(clean_path, enhanced_audio, df_state.sr())\n",
    "    \n",
    "    del model\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n",
    "    data, samplerate = sf.read(clean_path)\n",
    "    noise_level = 0.001\n",
    "    noise = np.random.randn(*data.shape)\n",
    "    data_with_cn = data + (noise * noise_level)\n",
    "    \n",
    "    final_path = input_path.replace(\".wav\", \"_final.wav\")\n",
    "    sf.write(final_path, data_with_cn, samplerate)\n",
    "    \n",
    "    if os.path.exists(clean_path): os.remove(clean_path)\n",
    "    return final_path\n",
    "\n",
    "def align_sentences_with_words(full_text: str, all_words: List[dict]) -> List[dict]:\n",
    "    sentences = kss.split_sentences(full_text)\n",
    "    aligned_segments = []\n",
    "    word_idx = 0\n",
    "    max_words = len(all_words)\n",
    "    \n",
    "    for sent in sentences:\n",
    "        if word_idx >= max_words: break\n",
    "        target_chars = sent.replace(\" \", \"\")\n",
    "        accumulated_chars = \"\"\n",
    "        start_time = all_words[word_idx]['start']\n",
    "        end_time = start_time\n",
    "        \n",
    "        while word_idx < max_words:\n",
    "            word_info = all_words[word_idx]\n",
    "            clean_word = word_info['word'].replace(\" \", \"\")\n",
    "            accumulated_chars += clean_word\n",
    "            end_time = word_info['end']\n",
    "            word_idx += 1\n",
    "            if len(accumulated_chars) >= len(target_chars): break\n",
    "        \n",
    "        aligned_segments.append({\"start\": start_time, \"end\": end_time, \"text\": sent})\n",
    "    return aligned_segments\n",
    "    \n",
    "def process_video_to_sentences(video_path: str) -> List[SentenceSegment]:\n",
    "    raw_audio = extract_audio_from_video(video_path)\n",
    "    voice_path = remove_noise_and_add_comfort(raw_audio)\n",
    "    \n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = whisper.load_model(\"large-v3-turbo\", device=device)\n",
    "    result = model.transcribe(voice_path, language=\"ko\", word_timestamps=True)\n",
    "    \n",
    "    all_words = []\n",
    "    for segment in result['segments']:\n",
    "        for word in segment['words']:\n",
    "            all_words.append({\"word\": word['word'].strip(), \"start\": word['start'], \"end\": word['end']})\n",
    "    \n",
    "    aligned_data = align_sentences_with_words(result['text'], all_words)\n",
    "    \n",
    "    segments = []\n",
    "    for idx, s in enumerate(aligned_data, start=1):\n",
    "        segments.append(SentenceSegment(idx, s[\"start\"], s[\"end\"], s[\"text\"]))\n",
    "    \n",
    "    del model\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "    \n",
    "    if os.path.exists(raw_audio): os.remove(raw_audio)\n",
    "    if os.path.exists(voice_path): os.remove(voice_path)\n",
    "    \n",
    "    return segments\n",
    "\n",
    "# =======================\n",
    "# 2. Solar ë¶„ì„ & í…ì„œ ì¶”ì¶œ í•¨ìˆ˜ \n",
    "# =======================\n",
    "def analyze_with_solar(structured_data):\n",
    "    print(f\"   â˜€ï¸ Solar ë¶„ì„ ì‹œì‘ ({len(structured_data)} ë¬¸ì¥)...\")\n",
    "    client = OpenAI(api_key=SOLAR_API_KEY, base_url=SOLAR_BASE_URL)\n",
    "    full_script = \"\\n\".join([f\"[{item['index']}] {item['text']}\" for item in structured_data])\n",
    "    \n",
    "    final_analysis_list = []\n",
    "    BATCH_SIZE = 20\n",
    "    \n",
    "    for i in range(0, len(structured_data), BATCH_SIZE):\n",
    "        batch = structured_data[i : i + BATCH_SIZE]\n",
    "        script_for_llm = \"\\n\".join([f\"[{item['index']}] {item['text']}\" for item in batch])\n",
    "\n",
    "        user_content = f\"\"\"\n",
    "[ì „ì²´ ëŒ€ë³¸ (Context)]\n",
    "{full_script}\n",
    "\n",
    "[ì´ë²ˆì— ë¶„ì„í•  íŒŒíŠ¸ (Target)]\n",
    "{script_for_llm}\n",
    "\"\"\"\n",
    "        system_prompt = \"\"\"\n",
    "ë„ˆëŠ” í•œêµ­ì–´ ë°œí‘œÂ·ìŠ¤í”¼ì¹˜ ì½”ì¹­ ì „ë¬¸ê°€ì´ë©°, Whisperê°€ ì¶”ì¶œí•œ ëŒ€ë³¸ ì „ì²´ë¥¼ ë¶„ì„í•´\n",
    "ê° ë¬¸ì¥ì´ ì²­ì¤‘ì„ ì„¤ë“í•˜ëŠ” ë° ì–¼ë§ˆë‚˜ â€˜í•µì‹¬ì ì´ê³  ê°•ì¡° ê°€ì¹˜â€™ë¥¼ ê°–ëŠ”ì§€ ì •ëŸ‰ì ìœ¼ë¡œ í‰ê°€í•œë‹¤.\n",
    "\n",
    "[ë§¤ìš° ì¤‘ìš”í•œ ê·œì¹™]\n",
    "1. ì…ë ¥ëœ ë¬¸ì¥ì˜ ê°œìˆ˜ì™€ ìˆœì„œë¥¼ ì •í™•íˆ ì§€ì¼œë¼.\n",
    "2. JSONì˜ analysis ë¦¬ìŠ¤íŠ¸ ê¸¸ì´ëŠ” ì…ë ¥ ë¬¸ì¥ ê°œìˆ˜ì™€ ì •í™•íˆ ê°™ì•„ì•¼ í•œë‹¤.\n",
    "3. analysis ë¦¬ìŠ¤íŠ¸ì˜ ê° í•­ëª©ì—ëŠ” ë°˜ë“œì‹œ index í•„ë“œë¥¼ í¬í•¨í•´ë¼.\n",
    "4. start_sec, end_sec ê°™ì€ ì‹œê°„ ì •ë³´ëŠ” ì¶œë ¥í•˜ì§€ ë§ˆë¼.\n",
    "5. ì˜¤ì§ index, corrected, emphasis_score, key_word, reason í•„ë“œë§Œ ì¶œë ¥í•˜ë¼.\n",
    "\n",
    "[Correction ê·œì¹™]\n",
    "- ëª…ë°±í•œ ì˜¤íƒ€ë§Œ ìˆ˜ì •í•˜ë¼.\n",
    "\n",
    "[Emphasis Score ê·œì¹™ (0.00 ~ 1.00)]\n",
    "- 0.81~1.00: í•µì‹¬ ë©”ì‹œì§€ (ê°•ì¡° í•„ìˆ˜)\n",
    "- 0.61~0.80: ì¤‘ìš” ì˜ˆì‹œ/ì§ˆë¬¸\n",
    "- 0.00~0.60: ì¼ë°˜ ì •ë³´\n",
    "\n",
    "[ì¶œë ¥ í˜•ì‹]\n",
    "- ì˜¤ì§ í•˜ë‚˜ì˜ JSON ê°ì²´ë§Œ ì¶œë ¥í•œë‹¤. ì˜ˆ: {\"analysis\": [...]}\n",
    "\"\"\"\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt}, \n",
    "                    {\"role\": \"user\", \"content\": user_content} \n",
    "                ],\n",
    "                model=MODEL_ID, temperature=0.0, response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            res = json.loads(completion.choices[0].message.content)\n",
    "            final_analysis_list.extend(res.get(\"analysis\", []))\n",
    "            print(f\"      -> {i+1} ~ {min(i+BATCH_SIZE, len(structured_data))} ë¬¸ì¥ ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"      âš ï¸ Solar API Err: {e}\")\n",
    "\n",
    "    llm_map = {item.get(\"index\"): item for item in final_analysis_list}\n",
    "    final_result = []\n",
    "\n",
    "    for origin in structured_data:\n",
    "        idx = origin[\"index\"]\n",
    "        merged = {\n",
    "            \"index\": idx,\n",
    "            \"start_sec\": origin[\"start\"],\n",
    "            \"end_sec\": origin[\"end\"]\n",
    "        }\n",
    "        if idx in llm_map:\n",
    "            t = llm_map[idx]\n",
    "            merged.update({\n",
    "                \"corrected\": t.get(\"corrected\", origin[\"text\"]),\n",
    "                \"emphasis_score\": float(t.get(\"emphasis_score\", 0.0)),\n",
    "                \"key_word\": t.get(\"key_word\", \"\"),\n",
    "                \"reason\": t.get(\"reason\", \"\")\n",
    "            })\n",
    "        else:\n",
    "            merged.update({\n",
    "                \"corrected\": origin[\"text\"],\n",
    "                \"emphasis_score\": 0.0,\n",
    "                \"key_word\": \"\",\n",
    "                \"reason\": \"API ëˆ„ë½\"\n",
    "            })\n",
    "        final_result.append(merged)\n",
    "        \n",
    "    return {\"analysis\": final_result}\n",
    "\n",
    "def extract_tensors(json_data):\n",
    "    print(f\"   ğŸ’ RoBERTa í…ì„œ ì¶”ì¶œ ì¤‘...\")\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-large\")\n",
    "        model = AutoModel.from_pretrained(\"klue/roberta-large\", output_hidden_states=True)\n",
    "    except:\n",
    "        print(\"   âŒ RoBERTa ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨\")\n",
    "        return []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    tensor_results = []\n",
    "    for item in json_data.get(\"analysis\", []):\n",
    "        text = item.get('corrected', '').strip()\n",
    "        if text:\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128).to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "            last_4_layers = outputs.hidden_states[-4:]\n",
    "            cls_list = [layer[:,0,:] for layer in last_4_layers]\n",
    "            sum_tensor = torch.stack(cls_list).sum(dim=0).cpu()\n",
    "            tensor_results.append(sum_tensor) \n",
    "        else:\n",
    "            tensor_results.append(torch.zeros(1, 1024))\n",
    "            \n",
    "    return tensor_results\n",
    "\n",
    "# =======================\n",
    "# 3. ë©”ì¸ ì‹¤í–‰ ë£¨í”„ \n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    target_extensions = ['*.mp4', '*.avi', '*.mkv', '*.mov']\n",
    "    video_files = []\n",
    "    for ext in target_extensions:\n",
    "        video_files.extend(glob.glob(os.path.join(VIDEO_DIR, ext)))\n",
    "    video_files.sort()\n",
    "    \n",
    "    print(f\"ğŸ“‚ ì´ {len(video_files)}ê°œì˜ ì˜ìƒì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.\\n\")\n",
    "\n",
    "    total_json_list = []\n",
    "    total_tensor_list = []\n",
    "\n",
    "    for i, video_path in enumerate(video_files, 1):\n",
    "        filename = os.path.basename(video_path) \n",
    "        file_id = filename.rsplit('.', 1)[0]    \n",
    "        \n",
    "        print(f\"[{i}/{len(video_files)}] ì²˜ë¦¬ ì¤‘: {filename}\")\n",
    "        \n",
    "        try:\n",
    "            sentences = process_video_to_sentences(video_path)\n",
    "            structured_data = [{\"index\": s.index, \"text\": s.text, \"start\": s.start, \"end\": s.end} for s in sentences]\n",
    "            \n",
    "            final_json = analyze_with_solar(structured_data)\n",
    "            \n",
    "            tensors = extract_tensors(final_json)\n",
    "            \n",
    "            current_analysis_list = final_json.get(\"analysis\", [])\n",
    "            for item in current_analysis_list:\n",
    "                item[\"video_path\"] = video_path  \n",
    "                item[\"video_filename\"] = filename \n",
    "            \n",
    "            total_json_list.extend(current_analysis_list)\n",
    "            if tensors:\n",
    "                total_tensor_list.extend(tensors)\n",
    "\n",
    "            save_json_path = os.path.join(RESULT_DIR, f\"{file_id}_text.json\")\n",
    "            save_tensor_path = os.path.join(RESULT_DIR, f\"{file_id}_tensor.pt\")\n",
    "            \n",
    "            with open(save_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(final_json, f, ensure_ascii=False, indent=4)\n",
    "            if tensors:\n",
    "                torch.save(tensors, save_tensor_path)\n",
    "            \n",
    "            print(f\"   âœ… ê°œë³„ ì²˜ë¦¬ ì™„ë£Œ: {len(current_analysis_list)} ë¬¸ì¥\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ {filename} ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    # =======================\n",
    "    # 4. ìµœì¢… ë³‘í•© íŒŒì¼ ì €ì¥\n",
    "    # =======================\n",
    "    print(\"=\" * 50)\n",
    "    print(\"ğŸš€ ëª¨ë“  ì˜ìƒ ì²˜ë¦¬ ì™„ë£Œ! ë³‘í•© íŒŒì¼ ìƒì„± ì¤‘...\")\n",
    "\n",
    "    final_merged_json = {\"analysis\": total_json_list}\n",
    "    merged_json_path = os.path.join(RESULT_DIR, \"total_text.json\")\n",
    "    with open(merged_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(final_merged_json, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    merged_tensor_path = os.path.join(RESULT_DIR, \"total_tensor.pt\")\n",
    "    if total_tensor_list:\n",
    "        torch.save(total_tensor_list, merged_tensor_path)\n",
    "        print(f\"âœ… [í†µí•© ì™„ë£Œ] í…ì„œ ê°œìˆ˜: {len(total_tensor_list)}ê°œ\")\n",
    "        print(f\"   ğŸ’¾ ì €ì¥ ê²½ë¡œ: {merged_tensor_path}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ ì €ì¥í•  í…ì„œê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    print(f\"âœ… [í†µí•© ì™„ë£Œ] JSON ë°ì´í„° ê°œìˆ˜: {len(total_json_list)}ê°œ\")\n",
    "    print(f\"   ğŸ’¾ ì €ì¥ ê²½ë¡œ: {merged_json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac750db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04f597d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ '/home/stu/ai_project/ì‹œì—°' ì—ì„œ íŒŒì¼ ë³‘í•©ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "   - ë°œê²¬ëœ íŒŒì¼ ìˆ˜: 3 ì„¸íŠ¸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 70.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ ë³‘í•©ëœ ë°ì´í„° ì €ì¥ ì¤‘...\n",
      "âœ… ì™„ë£Œ!\n",
      "   - JSON: /home/stu/ai_project/ì‹œì—°/total_text.json (ì´ 71 ë¬¸ì¥)\n",
      "   - Tensor: /home/stu/ai_project/ì‹œì—°/total_tensor.pt (ì´ 71 ê°œ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===== ì„¤ì • =====\n",
    "TEXT_OUTPUT_DIR = \"/home/stu/ai_project/ì‹œì—°\" \n",
    "SAVE_DIR = \"/home/stu/ai_project/ì‹œì—°\"\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "def merge_text_data(input_dir, save_dir):\n",
    "    json_files = sorted(glob.glob(os.path.join(input_dir, \"*_text.json\")))\n",
    "    \n",
    "    total_json_list = []\n",
    "    total_tensor_list = []\n",
    "    \n",
    "    print(f\"ğŸ“‚ '{input_dir}' ì—ì„œ íŒŒì¼ ë³‘í•©ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    print(f\"   - ë°œê²¬ëœ íŒŒì¼ ìˆ˜: {len(json_files)} ì„¸íŠ¸\")\n",
    "\n",
    "    for json_path in tqdm(json_files):\n",
    "        filename = os.path.basename(json_path)\n",
    "        file_id = filename.replace(\"_text.json\", \"\")\n",
    "        \n",
    "        tensor_path = os.path.join(input_dir, f\"{file_id}_tensor.pt\")\n",
    "        \n",
    "        if not os.path.exists(tensor_path):\n",
    "            print(f\"   âš ï¸ ê²½ê³ : í…ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ (Skip) - {file_id}\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                analysis_list = data.get(\"analysis\", [])\n",
    "            \n",
    "            tensors = torch.load(tensor_path)\n",
    "            \n",
    "            if len(analysis_list) != len(tensors):\n",
    "                print(f\"   âŒ ì˜¤ë¥˜: ë¬¸ì¥ ê°œìˆ˜ì™€ í…ì„œ ê°œìˆ˜ ë¶ˆì¼ì¹˜ ({file_id})\")\n",
    "\n",
    "                continue\n",
    "\n",
    "            for item in analysis_list:\n",
    "                item[\"video_filename\"] = file_id \n",
    "\n",
    "            total_json_list.extend(analysis_list)\n",
    "            \n",
    "            if isinstance(tensors, list):\n",
    "                total_tensor_list.extend(tensors)\n",
    "            else:\n",
    "                for i in range(tensors.size(0)):\n",
    "                    total_tensor_list.append(tensors[i])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ ({file_id}): {e}\")\n",
    "\n",
    "    # ===== ì €ì¥ =====\n",
    "    print(\"\\nğŸ’¾ ë³‘í•©ëœ ë°ì´í„° ì €ì¥ ì¤‘...\")\n",
    "    \n",
    "    final_json_path = os.path.join(save_dir, \"total_text.json\")\n",
    "    with open(final_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"analysis\": total_json_list}, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    final_tensor_path = os.path.join(save_dir, \"total_tensor.pt\")\n",
    "    torch.save(total_tensor_list, final_tensor_path)\n",
    "    \n",
    "    print(f\"âœ… ì™„ë£Œ!\")\n",
    "    print(f\"   - JSON: {final_json_path} (ì´ {len(total_json_list)} ë¬¸ì¥)\")\n",
    "    print(f\"   - Tensor: {final_tensor_path} (ì´ {len(total_tensor_list)} ê°œ)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    merge_text_data(TEXT_OUTPUT_DIR, SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e355d370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
